{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Validation Report:\n",
      "Test Accuracy: 0.9708029197080292\n",
      "Class Distribution:\n",
      " quality_label\n",
      "0    0.532847\n",
      "2    0.255474\n",
      "1    0.211679\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwin_jayan/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:06:29] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/ashwin_jayan/EXTRACT/ML_Model/Files/Pickle/cluster_labels.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This script performs clustering and classification on user profiles using GitHub data.\n",
    " \n",
    "1. Loads the dataset and fills missing values in relevant columns.\n",
    "2. Applies a Power Transformer to normalize specific numeric features.\n",
    "3. Uses Gaussian Mixture Models (GMM) to determine the optimal number of clusters.\n",
    "4. Assigns a \"quality label\" to each cluster based on aggregated metrics.\n",
    "5. Splits the data into training and test sets for classification.\n",
    "6. Trains an XGBoost classifier to predict the quality label.\n",
    "7. Saves the trained model, preprocessor, and label mappings for future use.'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"/home/ashwin_jayan/EXTRACT/ML_Model/Files/train_data.csv\")\n",
    "\n",
    "cluster_quality_cols = [\n",
    "    'commit_score', 'total_stars',\n",
    "    'code_reviews_count', 'total_commits_last_year'\n",
    "]\n",
    "df[cluster_quality_cols] = df[cluster_quality_cols].fillna(0)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('power_transform', PowerTransformer(), [\n",
    "        'public_repos', 'followers', 'total_stars', \n",
    "        'total_forks', 'commit_score'\n",
    "    ]),\n",
    "], remainder='passthrough')\n",
    "\n",
    "X = df.drop(columns=['job role','username', 'email', 'user_url', 'avatar_url'])\n",
    "X_trans = preprocessor.fit_transform(X)\n",
    "\n",
    "def find_optimal_clusters(X, max_clusters=8):\n",
    "    bic = []\n",
    "    for n in range(1, max_clusters+1):\n",
    "        gmm = GaussianMixture(n_components=n, random_state=42)\n",
    "        gmm.fit(X)\n",
    "        bic.append(gmm.bic(X))\n",
    "    return np.argmin(bic) + 1\n",
    "\n",
    "optimal_clusters = find_optimal_clusters(X_trans)\n",
    "gmm = GaussianMixture(n_components=optimal_clusters, random_state=42)\n",
    "clusters = gmm.fit_predict(X_trans)\n",
    "df['cluster'] = clusters\n",
    "\n",
    "cluster_quality = df.groupby('cluster').agg({\n",
    "    'commit_score': 'mean',\n",
    "    'total_stars': 'mean',\n",
    "    'code_reviews_count': 'mean',\n",
    "    'total_commits_last_year': 'median'\n",
    "}).mean(axis=1)\n",
    "\n",
    "\n",
    "quality_labels = pd.qcut(cluster_quality, q=[0, 0.2, 0.8, 1], \n",
    "                        labels=[0, 1, 2])  \n",
    "label_mapping = {\n",
    "    0: 'bad',\n",
    "    1: 'good', \n",
    "    2: 'exceptional'\n",
    "}\n",
    "df['quality_label'] = df['cluster'].map(quality_labels.to_dict())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_trans, df['quality_label'].astype(int),  \n",
    "    test_size=0.2, stratify=df['quality_label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.9,\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(label_mapping, '/home/ashwin_jayan/EXTRACT/ML_Model/Files/Pickle/label_mapping.pkl')\n",
    "\n",
    "print(\"Classifier Validation Report:\")\n",
    "print(\"Test Accuracy:\", clf.score(X_test, y_test))\n",
    "print(\"Class Distribution:\\n\", y_test.value_counts(normalize=True))\n",
    "\n",
    "joblib.dump(preprocessor, '/home/ashwin_jayan/EXTRACT/ML_Model/Files/Pickle/preprocessor.pkl')\n",
    "joblib.dump(clf, '/home/ashwin_jayan/EXTRACT/ML_Model/Files/Pickle/xgb_classifier.pkl')\n",
    "joblib.dump(quality_labels, '/home/ashwin_jayan/EXTRACT/ML_Model/Files/Pickle/cluster_labels.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
