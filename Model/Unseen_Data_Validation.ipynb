{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 90 candidates to /home/ashwin_jayan/EXTRACT/ML_Model/Files/best_candidates_per_role.csv\n",
      "Job roles in output: ['Web Developer' 'Data Science' 'Java Developer']\n"
     ]
    }
   ],
   "source": [
    "''' This script identifies and ranks exceptional users from GitHub profile data using a trained classification model.\n",
    "\n",
    "1. Loads the pre-trained preprocessor, XGBoost classifier, and label mappings.\n",
    "2. Reads and combines user profile data from multiple CSV files.\n",
    "3. Removes duplicate entries based on the 'username' column.\n",
    "4. Ensures all required feature columns are present in the dataset.\n",
    "5. Applies the preprocessor to transform numeric features.\n",
    "6. Predicts user quality labels using the trained classifier.\n",
    "7. Assigns a quality ranking to each user based on predefined categories.\n",
    "8. Computes a custom score based on relevant GitHub activity metrics.\n",
    "9. Selects the top 30 candidates per job role based on quality and score.\n",
    "10. Saves the final ranked list of candidates to a CSV file. '''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "BASE_DIR = \"/home/ashwin_jayan/EXTRACT/ML_Model/Files\"\n",
    "\n",
    "def predict_exceptional_users():\n",
    "    preprocessor = joblib.load(os.path.join(BASE_DIR, 'Pickle/preprocessor.pkl'))\n",
    "    clf = joblib.load(os.path.join(BASE_DIR, 'Pickle/xgb_classifier.pkl'))\n",
    "    label_mapping = joblib.load(os.path.join(BASE_DIR, 'Pickle/label_mapping.pkl'))\n",
    "    \n",
    "    input_files = [\n",
    "        os.path.join(BASE_DIR, \"data_science_data.csv\"),\n",
    "        os.path.join(BASE_DIR, \"java_developer_data.csv\"),\n",
    "        os.path.join(BASE_DIR, \"web_developer_data.csv\")\n",
    "    ]\n",
    "    \n",
    "    new_data = pd.concat([pd.read_csv(f) for f in input_files], ignore_index=True)\n",
    "    \n",
    "    unique_identifier = 'username'  \n",
    "    new_data = new_data.drop_duplicates(subset=[unique_identifier])\n",
    "\n",
    "    required_columns = [\n",
    "        'public_repos', 'followers', 'total_stars',\n",
    "        'total_forks', 'total_issues_opened', 'total_issues_closed',\n",
    "        'total_commits_last_year', 'total_commits_all_time',\n",
    "        'avg_issue_close_time', 'contributed_repos', 'code_reviews_count',\n",
    "        'commit_score', 'feature_1', 'feature_2', 'feature_3',\n",
    "        'total_pr_merged', 'avg_commits_per_month', 'job role'\n",
    "    ]\n",
    "    \n",
    "    missing = set(required_columns) - set(new_data.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in input data: {missing}\")\n",
    "\n",
    "    X_new = preprocessor.transform(new_data[required_columns[:-1]])  \n",
    "    pred_labels = clf.predict(X_new)\n",
    "    \n",
    "    new_data['predicted_quality'] = [label_mapping[l] for l in pred_labels]\n",
    "    \n",
    "    quality_order = {'exceptional': 0, 'good': 1, 'bad': 2}\n",
    "    new_data['quality_rank'] = new_data['predicted_quality'].map(quality_order)\n",
    "    new_data['score'] = (\n",
    "        new_data['followers'] * 30. +\n",
    "        new_data['total_stars'] * 2 +\n",
    "        new_data['commit_score'] * 3 +\n",
    "        new_data['code_reviews_count'] * 1 +\n",
    "        new_data['total_pr_merged'] * 2\n",
    "    ) / 9 \n",
    "    \n",
    "    best_candidates = (\n",
    "        new_data.sort_values(by=['quality_rank', 'score'], ascending=[True, False])\n",
    "        .groupby('job role')\n",
    "        .head(30)  \n",
    "    )\n",
    "\n",
    "    output_path = os.path.join(BASE_DIR, \"best_candidates_per_role.csv\")\n",
    "    best_candidates.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Saved {len(best_candidates)} candidates to {output_path}\")\n",
    "    print(\"Job roles in output:\", best_candidates['job role'].unique())\n",
    "\n",
    "predict_exceptional_users()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
